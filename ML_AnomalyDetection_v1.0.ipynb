{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nixtla import NixtlaClient\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "data_frames_to_merge = []\n",
    "\n",
    "\n",
    "# Base folder path (replace with your actual path)\n",
    "base_folder = './data'\n",
    "time_col = 'timestamp'\n",
    "target_col = 'target'\n",
    "number_anomalies_predict=20    \n",
    "\n",
    "# List of folders\n",
    "#folders = ['1', '2', '3', '4', '5', '6', '7']\n",
    "folders = ['1', '2', '3']\n",
    "\n",
    "data_columns = ['P-PDG', 'P-TPT', 'T-TPT', 'P-MON-CKP', 'T-JUS-CKP', 'P-JUS-CKGL', 'T-JUS-CKGL', 'QGL']\n",
    "\n",
    "\n",
    "nixtla_client = NixtlaClient(\n",
    "    # defaults to os.environ.get(\"NIXTLA_API_KEY\")\n",
    "    api_key = 'nixak-ydVyUIawnVh68qhFTgxxWrCKzLNvOKmLVNpDr24m94DHR4e1sYYkntIF0iyIhjhUQLmjEUypp4vGORXe'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_online(df, time_col, target_col):\n",
    "    \"\"\"Call the TimeGPT Nixtla API to detect anomalies in the target column of a DataFrame.\"\"\"\n",
    "    return nixtla_client.detect_anomalies_online(\n",
    "        df = df,\n",
    "        time_col=time_col,\n",
    "        target_col=target_col,\n",
    "        freq='s',                      # Specify the frequency of the data\n",
    "        h=30,                           # Specify the forecast horizon\n",
    "        level=80,                       # Set the confidence level for anomaly detection\n",
    "        detection_size=number_anomalies_predict,              # How many steps you want for analyzing anomalies\n",
    "        threshold_method = 'multivariate',  # Specify the threshold_method as 'multivariate'    \n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to plot anomalies\n",
    "def plot_anomaly(df, anomaly_df, time_col = 'ts', target_col = 'y'):\n",
    "    \"\"\"Plot anomaly detection.\"\"\"\n",
    "    merged_df = pd.merge(df.tail(300), anomaly_df[[time_col, 'anomaly', 'TimeGPT']], on=time_col, how='left')\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.plot(merged_df[time_col], merged_df[target_col], label='y', color='navy', alpha=0.8)\n",
    "    plt.plot(merged_df[time_col], merged_df['TimeGPT'], label='TimeGPT', color='orchid', alpha=0.7)\n",
    "    plt.scatter(merged_df.loc[merged_df['anomaly'] == True, time_col], merged_df.loc[merged_df['anomaly'] == True, target_col], color='orchid', label='Anomalies Detected')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "\n",
    "def detect_anomalies(df, ini_row, end_row):\n",
    "    \"\"\"General function to identify an anomaly in a dataset using TimeGPT Nixtla API\"\"\"\n",
    "    data_frame_target = pd.DataFrame()\n",
    "    type_anomaly = 0\n",
    "    # Convert numeric columns back to float\n",
    "    for col in df.columns:\n",
    "        # Check if the column can be converted to numeric (including decimals)\n",
    "        if (col in data_columns):\n",
    "            try:\n",
    "                df.loc[:, col] = pd.to_numeric(df[col])\n",
    "            except ValueError:\n",
    "                pass        \n",
    "            df.loc[:, col]= df[[col]].replace('', 0) \n",
    "            scaler = MinMaxScaler()              \n",
    "            df.loc[:, col] = scaler.fit_transform(df[[col]])\n",
    "        if (col in ['timestamp']): \n",
    "            try:\n",
    "                df.loc[:, col] = pd.to_datetime(df[col])\n",
    "            except ValueError:\n",
    "                pass                                      \n",
    "        if (col in ['class']):                              \n",
    "            data_frame_target.loc[:, 'anomaly'] = df[col]\n",
    "            max_val = data_frame_target.max(skipna=True).max()\n",
    "            if pd.isna(max_val):\n",
    "                type_anomaly = None  # or set a default like -1 or 0\n",
    "            else:\n",
    "                type_anomaly = int(max_val)\n",
    "                if type_anomaly > 100:\n",
    "                    type_anomaly = type_anomaly - 100\n",
    "\n",
    "            data_frame_target.loc[:, 'anomaly']  = df[col].apply(lambda x: True if x != 0 and x != '' else False)  \n",
    "                       \n",
    "    common_cols = list(set(df.columns) & set(data_columns))\n",
    "\n",
    "        \n",
    "    df.loc[:, 'target'] = df[common_cols].sum(axis=1, min_count=1)\n",
    "    df = df.drop('class', axis=1)    \n",
    "            \n",
    "    df = df.iloc[ini_row:end_row].reset_index(drop=True)    \n",
    "    data_frame_target= data_frame_target.iloc[ini_row:end_row].tail(number_anomalies_predict).reset_index(drop=True)    \n",
    "    \n",
    "    data_frame_anomaly = detect_anomalies_online(df, time_col, target_col)\n",
    "    \n",
    "    print(\"Data frame actual anomalies\")\n",
    "    print(data_frame_target.shape)\n",
    "    print(\"Data frame anomalies predicted\")\n",
    "    print(data_frame_anomaly.shape)\n",
    "\n",
    "    accuracy = accuracy_score(data_frame_anomaly['anomaly'], data_frame_target['anomaly'])\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    return data_frame_anomaly, type_anomaly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_anomalies_file(type_anomaly, file_name, ini_row, end_row):\n",
    "    \"\"\"Function to identify an anomaly in a specific log file and range of rows\"\"\"\n",
    "\n",
    "    print(\"\\nCALL FUNCTION TO DETECT ANOMALIES IN MACHINE LEARNING OR LLM MODEL\\n\")\n",
    "    folder_path = os.path.join(base_folder, str(type_anomaly))\n",
    "    print(f'Function detect_anomalies_file: {type_anomaly}, {folder_path}, {file_name}, {ini_row}, {end_row}')\n",
    "    if file_name.startswith('WELL-'):\n",
    "        print(f'Processing file: {file_name}')\n",
    "        file_path = os.path.join(folder_path, file_name)    \n",
    "        df = pd.DataFrame()        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        return detect_anomalies(df, ini_row, end_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_dates(type_anomaly, start_date, end_date):\n",
    "    \"\"\"Function to identify an anomaly in a specific range of dates and specific id or type of anomaly\"\"\" \n",
    "\n",
    "    print(\"\\nCALL FUNCTION TO DETECT ANOMALIES IN MACHINE LEARNING OR LLM MODEL\\n\")\n",
    "    print(f'Function detect_anomalies_dates: {type_anomaly}, {start_date}, {end_date}')\n",
    "    type_anomaly_str = str(type_anomaly)\n",
    "    folder_path = os.path.join(base_folder, type_anomaly_str)\n",
    "\n",
    "    for file_name in os.listdir(folder_path):   \n",
    "        if file_name.startswith('WELL-'):\n",
    "            print(f'Processing file: {file_name}')\n",
    "            file_path = os.path.join(folder_path, file_name)            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Define the start and end dates and times\n",
    "            start_datetime = parse(start_date)\n",
    "            end_datetime = parse(end_date)\n",
    "            \n",
    "             # Ensure start_datetime and end_datetime are timezone-aware (UTC)\n",
    "            if start_datetime.tzinfo is None:\n",
    "                start_datetime = start_datetime.replace(tzinfo=timezone.utc)\n",
    "            if end_datetime.tzinfo is None:\n",
    "                end_datetime = end_datetime.replace(tzinfo=timezone.utc)\n",
    "\n",
    "            # Convert 'timestamp' column to datetime and make it timezone-aware (UTC)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "            # Filter the dataframe\n",
    "            filtered_df = df[(df['timestamp'] >= start_datetime) & (df['timestamp'] <= end_datetime)]  \n",
    "\n",
    "            if filtered_df.shape[0] > 0:\n",
    "                return detect_anomalies(filtered_df, 0, filtered_df.shape[0])\n",
    "            else:\n",
    "                return None         \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_all_anomalies_dates(start_date, end_date):\n",
    "    \"\"\"Function to identify an anomaly in a specific range of dates\"\"\" \n",
    "\n",
    "    print(\"\\nCALL FUNCTION TO DETECT ANOMALIES IN MACHINE LEARNING OR LLM MODEL\\n\")\n",
    "    print(f'Function detect_all_anomalies_dates: {start_date}, {end_date}')\n",
    "\n",
    "    for folder in folders:    \n",
    "        folder_path = os.path.join(base_folder, folder)\n",
    "        print(f'Processing folder: {folder}')\n",
    "        # Iterate over the files in the folder    \n",
    "        for file_name in os.listdir(folder_path):   \n",
    "            if file_name.startswith('WELL-'):\n",
    "                print(f'Processing file: {file_name}')\n",
    "                file_path = os.path.join(folder_path, file_name)            \n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Define the start and end dates and times\n",
    "                start_datetime = parse(start_date)\n",
    "                end_datetime = parse(end_date)\n",
    "                \n",
    "                # Ensure start_datetime and end_datetime are timezone-aware (UTC)\n",
    "                if start_datetime.tzinfo is None:\n",
    "                    start_datetime = start_datetime.replace(tzinfo=timezone.utc)\n",
    "                if end_datetime.tzinfo is None:\n",
    "                    end_datetime = end_datetime.replace(tzinfo=timezone.utc)\n",
    "\n",
    "                # Convert 'timestamp' column to datetime and make it timezone-aware (UTC)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "                # Filter the dataframe\n",
    "                filtered_df = df[(df['timestamp'] >= start_datetime) & (df['timestamp'] <= end_datetime)] \n",
    "\n",
    "                if filtered_df.shape[0] > 0:\n",
    "                    return detect_anomalies(filtered_df, 0, filtered_df.shape[0])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_all_anomalies_dates_by_parameter(start_date, end_date, parameter):\n",
    "    \"\"\"Function to identify an anomaly in a specific range of dates and using an specific parameter desviation\"\"\" \n",
    "\n",
    "    print(\"\\nCALL FUNCTION TO DETECT ANOMALIES IN MACHINE LEARNING OR LLM MODEL\\n\")\n",
    "    print(f'Function detect_all_anomalies_dates_by_parameter: {start_date}, {end_date}, {parameter}')\n",
    "\n",
    "    for folder in folders:    \n",
    "        folder_path = os.path.join(base_folder, folder)\n",
    "        print(f'Processing folder: {folder}')\n",
    "        # Iterate over the files in the folder    \n",
    "        for file_name in os.listdir(folder_path):   \n",
    "            if file_name.startswith('WELL-'):\n",
    "                print(f'Processing file: {file_name}')\n",
    "                file_path = os.path.join(folder_path, file_name)            \n",
    "                # Read the CSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path)\n",
    "\n",
    "                # Define the start and end dates and times\n",
    "                start_datetime = parse(start_date)\n",
    "                end_datetime = parse(end_date)\n",
    "                \n",
    "                # Ensure start_datetime and end_datetime are timezone-aware (UTC)\n",
    "                if start_datetime.tzinfo is None:\n",
    "                    start_datetime = start_datetime.replace(tzinfo=timezone.utc)\n",
    "                if end_datetime.tzinfo is None:\n",
    "                    end_datetime = end_datetime.replace(tzinfo=timezone.utc)\n",
    "\n",
    "                # Convert 'timestamp' column to datetime and make it timezone-aware (UTC)\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "                \n",
    "\n",
    "                # Filter the dataframe\n",
    "                filtered_df = df[(df['timestamp'] >= start_datetime) & (df['timestamp'] <= end_datetime)]            \n",
    "\n",
    "\n",
    "                if filtered_df.shape[0] > 0:\n",
    "                    # Select only timestamp, parameter and class columns\n",
    "                    selected_parameter_df = filtered_df[[\"timestamp\", parameter, \"class\"]]\n",
    "                    return detect_anomalies(selected_parameter_df, 0, selected_parameter_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adrid\\AppData\\Local\\Temp\\ipykernel_40692\\953415535.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[False False False ...  True  True  True]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data_frame_target.loc[:, 'anomaly']  = df[col].apply(lambda x: True if x != 0 and x != '' else False)\n",
      "C:\\Users\\adrid\\AppData\\Local\\Temp\\ipykernel_40692\\953415535.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'target'] = df[common_cols].sum(axis=1, min_count=1)\n",
      "INFO:nixtla.nixtla_client:Validating inputs...\n",
      "INFO:nixtla.nixtla_client:Preprocessing dataframes...\n",
      "INFO:nixtla.nixtla_client:Using future exogenous features: ['T-JUS-CKP']\n",
      "INFO:nixtla.nixtla_client:Calling Online Anomaly Detector Endpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function detect_all_anomalies_dates: 2014-01-24T19:00:00Z, 2014-01-24T22:00:00Z\n",
      "Processing folder: 1\n",
      "Processing file: WELL-00001_20140124213136.csv\n",
      "Data frame actual anomalies\n",
      "(20, 1)\n",
      "Data frame anomalies predicted\n",
      "(20, 7)\n",
      "Accuracy: 1.0\n",
      "type_anomaly 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data_frame_anomaly, type_anomaly = detect_anomalies_dates(1, '2014-01-24T21:00:00Z', '2014-01-24T23:00:00Z')\n",
    "#print(data_frame_anomaly)\n",
    "#detect_anomalies_file (1, \"WELL-00001_20140124213136.csv\", 1200, 1700)\n",
    "\n",
    "#data_frame_anomaly, type_anomaly = detect_all_anomalies_dates('2014-01-24T19:00:00Z', '2014-01-24T22:00:00Z')\n",
    "#print(\"type_anomaly\", type_anomaly)\n",
    "\n",
    "data_frame_anomaly, type_anomaly = detect_all_anomalies_dates_by_parameter('2014-01-24T19:00:00Z', '2014-01-24T22:00:00Z', 'T-JUS-CKP')\n",
    "print(\"type_anomaly\", type_anomaly)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_capstoneproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
